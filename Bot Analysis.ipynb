{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bot=final.copy()\n",
    "dftot=df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[[\"username\",\"tweet\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bot[0] = df_bot[0].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftot[\"username\"] = dftot[\"username\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bot = df_bot.merge(dftot, left_on = 0, right_on = \"username\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bot = df_bot[(df_bot[\"universal\"] > 0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bot.drop([0], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(x):\n",
    "    return str(x).encode('ascii', 'ignore').decode('UTF-8')\n",
    "\n",
    "df_bot.tweet=df_bot.tweet.str.replace(r'[\\U0001F600-\\U0001F64F]', r'', regex=True)\n",
    "df_bot.tweet=df_bot.tweet.str.replace(r'[\\U0001F300-\\U0001F5FF]', r'', regex=True)\n",
    "df_bot.tweet=df_bot.tweet.str.replace(r'[\\U0001F680-\\U0001F6FF]', r'', regex=True)\n",
    "df_bot.tweet=df_bot.tweet.str.replace(r'[\\U0001F1E0-\\U0001F1FF]', r'', regex=True)\n",
    "df_bot.tweet=df_bot.tweet.str.replace(r'[\\U0001F300-\\U0001F5FF]', r'', regex=True)\n",
    "\n",
    "#eliminazione emoji\n",
    "\n",
    "df_bot.tweet = df_bot.tweet.str.lower() \n",
    "#convert text to lower-case\n",
    "\n",
    "df_bot.tweet=df_bot.tweet.str.replace(r'((www\\.[^\\s]+)|(https?://[^\\s]+))', r'', regex=True)\n",
    "#toglie link\n",
    "\n",
    "df_bot.tweet=df_bot.tweet.str.replace(r'@[^\\s]+', r'', regex=True)\n",
    "#toglie username\n",
    "\n",
    "df_bot.tweet=df_bot.tweet.str.replace(r'\\n', r' ', regex=True)\n",
    "#sostituisce \\n con spazio\n",
    "\n",
    "df_bot.tweet=df_bot.tweet.str.replace(r'#([^\\s]+)', r'\\1', regex=True)\n",
    "#toglie hashtag\n",
    "\n",
    "df_bot['tokenized_text'] =  df_bot['tweet'].apply(word_tokenize) \n",
    "#tokenize in una nuova colonna\n",
    "\n",
    "df_bot.tweet=df_bot.tweet.str.replace(r'[.;:!\\?,\\\"()\\[\\]+<>]', r'', regex=True)\n",
    "df_bot.tweet=df_bot.tweet.str.replace(r'(<br\\s*/><br\\s*/>)|(\\-)|(\\/)', r' ', regex=True)\n",
    "\n",
    "#elimina punteggiatura e simboli\n",
    "\n",
    "\n",
    "\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "         u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "         u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "         u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "         u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "         u\"\\U00002702-\\U000027B0\"\n",
    "         u\"\\U000024C2-\\U0001F251\"\n",
    "         \"]+\", flags=re.UNICODE)\n",
    "#HappyEmoticons\n",
    "emoticons_happy = set([\n",
    "    ':-)', ':)', ';)', ':o)', ':]', ':3', ':c)', ':>', '=]', '8)', '=)', ':}',\n",
    "    ':^)', ':-D', ':D', '8-D', '8D', 'x-D', 'xD', 'X-D', 'XD', '=-D', '=D',\n",
    "    '=-3', '=3', ':-))', \":'-)\", \":')\", ':*', ':^*', '>:P', ':-P', ':P', 'X-P',\n",
    "    'x-p', 'xp', 'XP', ':-p', ':p', '=p', ':-b', ':b', '>:)', '>;)', '>:-)',\n",
    "    '<3'\n",
    "    ])\n",
    "\n",
    "# Sad Emoticons\n",
    "emoticons_sad = set([\n",
    "    ':L', ':-/', '>:/', ':S', '>:[', ':@', ':-(', ':[', ':-||', '=L', ':<',\n",
    "    ':-[', ':-<', '=\\\\', '=/', '>:(', ':(', '>.<', \":'-(\", \":'(\", ':\\\\', ':-c',\n",
    "    ':c', ':{', '>:\\\\', ';('\n",
    "    ])\n",
    "\n",
    "emoticons = emoticons_happy.union(emoticons_sad)\n",
    "\n",
    "def clean_tweets(tweet):\n",
    " \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(tweet)\n",
    "#after tweepy preprocessing the colon symbol left remain after      #removing mentions\n",
    "    tweet = re.sub(r':', '', tweet)\n",
    "    tweet = re.sub(r'‚Ä¶', '', tweet)\n",
    "#replace consecutive non-ASCII characters with a space\n",
    "    tweet = re.sub(r'[^\\x00-\\x7F]+',' ', tweet)\n",
    "#remove emojis from tweet\n",
    "    tweet = emoji_pattern.sub(r'', tweet)\n",
    "#filter using NLTK library append it to a string\n",
    "    filtered_tweet = [w for w in word_tokens if not w in stop_words]\n",
    "    filtered_tweet = []\n",
    "#looping through conditions\n",
    "    for w in word_tokens:\n",
    "#check tokens against stop words , emoticons and punctuations\n",
    "        if w not in stop_words and w not in emoticons:\n",
    "            filtered_tweet.append(w)\n",
    "    return ' '.join(filtered_tweet)\n",
    "    #print(word_tokens)\n",
    "    #print(filtered_sentence)return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bot.tweet.apply(lambda x : clean_tweets(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop =stopwords.words('english')\n",
    "stop[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = string.punctuation\n",
    "print(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bot.tweet.apply(lambda x : clean_tweets(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.array(Image.open(\"/Users/alessandromotta/Downloads/logo.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=' '.join(df_bot['tweet'].tolist())\n",
    "wordcloud = WordCloud(\n",
    "background_color=\"white\",\n",
    "#mask = mask,\n",
    "max_words=500,\n",
    "width=1800,\n",
    "height=1400\n",
    ").generate(temp)\n",
    "plt.figure(figsize = (12,12))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
